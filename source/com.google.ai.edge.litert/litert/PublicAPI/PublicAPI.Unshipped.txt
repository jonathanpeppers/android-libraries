#nullable enable
Google.AI.Edge.LiteRT.Accelerator
Google.AI.Edge.LiteRT.Accelerator.Companion
Google.AI.Edge.LiteRT.Accelerator.Value.get -> int
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.BuiltinNpuAcceleratorProvider(Android.Content.Context! context) -> void
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.BuiltinNpuAcceleratorProvider(Android.Content.Context! context, Google.AI.Edge.LiteRT.INpuCompatibilityChecker! npuCompatibilityChecker) -> void
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.DownloadLibrary(Kotlin.Coroutines.IContinuation! _completion) -> Java.Lang.Object?
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.IsDeviceSupported.get -> bool
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.IsLibraryReady.get -> bool
Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.LibraryDir.get -> string!
Google.AI.Edge.LiteRT.CompiledModel
Google.AI.Edge.LiteRT.CompiledModel.Companion
Google.AI.Edge.LiteRT.CompiledModel.Companion.Create(Android.Content.Res.AssetManager! assetManager, string! assetName) -> Google.AI.Edge.LiteRT.CompiledModel!
Google.AI.Edge.LiteRT.CompiledModel.Companion.Create(Android.Content.Res.AssetManager! assetManager, string! assetName, Google.AI.Edge.LiteRT.CompiledModel.Options! options) -> Google.AI.Edge.LiteRT.CompiledModel!
Google.AI.Edge.LiteRT.CompiledModel.Companion.Create(Android.Content.Res.AssetManager! assetManager, string! assetName, Google.AI.Edge.LiteRT.CompiledModel.Options! options, Google.AI.Edge.LiteRT.Environment? optionalEnv) -> Google.AI.Edge.LiteRT.CompiledModel!
Google.AI.Edge.LiteRT.CompiledModel.Companion.Create(string! filePath) -> Google.AI.Edge.LiteRT.CompiledModel!
Google.AI.Edge.LiteRT.CompiledModel.Companion.Create(string! filePath, Google.AI.Edge.LiteRT.CompiledModel.Options! options) -> Google.AI.Edge.LiteRT.CompiledModel!
Google.AI.Edge.LiteRT.CompiledModel.Companion.Create(string! filePath, Google.AI.Edge.LiteRT.CompiledModel.Options! options, Google.AI.Edge.LiteRT.Environment? optionalEnv) -> Google.AI.Edge.LiteRT.CompiledModel!
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.Component1() -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.Component2() -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.Component3() -> string?
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.Copy(Java.Lang.Integer? numThreads, Java.Lang.Integer? xnnPackFlags, string? xnnPackWeightCachePath) -> Google.AI.Edge.LiteRT.CompiledModel.CpuOptions!
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.CpuOptions() -> void
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.CpuOptions(Java.Lang.Integer? numThreads, Java.Lang.Integer? xnnPackFlags, string? xnnPackWeightCachePath) -> void
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.NumThreads.get -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.XnnPackFlags.get -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.XnnPackWeightCachePath.get -> string?
Google.AI.Edge.LiteRT.CompiledModel.CreateInputBuffer(string! inputName, string! signature) -> Google.AI.Edge.LiteRT.TensorBuffer!
Google.AI.Edge.LiteRT.CompiledModel.CreateInputBuffers() -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.CreateInputBuffers(int signatureIndex) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.CreateInputBuffers(string! signature) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.CreateOutputBuffer(string! outputName, string! signature) -> Google.AI.Edge.LiteRT.TensorBuffer!
Google.AI.Edge.LiteRT.CompiledModel.CreateOutputBuffers() -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.CreateOutputBuffers(int signatureIndex) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.CreateOutputBuffers(string! signature) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.GetInputBufferRequirements(string! inputName, string! signature) -> Google.AI.Edge.LiteRT.TensorBufferRequirements!
Google.AI.Edge.LiteRT.CompiledModel.GetInputTensorType(string! inputName, string! signature) -> Google.AI.Edge.LiteRT.TensorType!
Google.AI.Edge.LiteRT.CompiledModel.GetOutputBufferRequirements(string! outputName, string! signature) -> Google.AI.Edge.LiteRT.TensorBufferRequirements!
Google.AI.Edge.LiteRT.CompiledModel.GetOutputTensorType(string! outputName, string! signature) -> Google.AI.Edge.LiteRT.TensorType!
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.AllowSrcQuantizedFcConvOps.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component1() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component10() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component11() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component12() -> string?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component13() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component14() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component15() -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component2() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component3() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component4() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component5() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component6() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component7() -> string?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component8() -> string?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Component9() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.ConstantTensorSharing.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Copy(Java.Lang.Boolean? constantTensorSharing, Java.Lang.Boolean? infiniteFloatCapping, Java.Lang.Boolean? allowSrcQuantizedFcConvOps, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision? precision, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType? bufferStorageType, Java.Lang.Boolean? preferTextureWeights, string? serializationDir, string? modelCacheKey, Java.Lang.Boolean? serializeProgramCache, Java.Lang.Boolean? serializeExternalTensors, Java.Lang.Boolean? externalTensorsMode, string? externalTensorPattern, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend? backend, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority? priority, Java.Lang.Integer? numStepsOfCommandBufferPreparations) -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions!
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.ExternalTensorPattern.get -> string?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.ExternalTensorsMode.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.GetBackend() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.GetBufferStorageType() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.GetPrecision() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.GetPriority() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.GpuOptions() -> void
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.GpuOptions(Java.Lang.Boolean? constantTensorSharing, Java.Lang.Boolean? infiniteFloatCapping, Java.Lang.Boolean? allowSrcQuantizedFcConvOps, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision? precision, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType? bufferStorageType, Java.Lang.Boolean? preferTextureWeights, string? serializationDir, string? modelCacheKey, Java.Lang.Boolean? serializeProgramCache, Java.Lang.Boolean? serializeExternalTensors, Java.Lang.Boolean? externalTensorsMode, string? externalTensorPattern, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend? backend, Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority? priority, Java.Lang.Integer? numStepsOfCommandBufferPreparations) -> void
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.InfiniteFloatCapping.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.ModelCacheKey.get -> string?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.NumStepsOfCommandBufferPreparations.get -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.PreferTextureWeights.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.SerializationDir.get -> string?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.SerializeExternalTensors.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.SerializeProgramCache.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.Options
Google.AI.Edge.LiteRT.CompiledModel.Options.Companion
Google.AI.Edge.LiteRT.CompiledModel.Options.Companion.CPU.get -> Google.AI.Edge.LiteRT.CompiledModel.Options!
Google.AI.Edge.LiteRT.CompiledModel.Options.CpuOptions.get -> Google.AI.Edge.LiteRT.CompiledModel.CpuOptions?
Google.AI.Edge.LiteRT.CompiledModel.Options.CpuOptions.set -> void
Google.AI.Edge.LiteRT.CompiledModel.Options.GpuOptions.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions?
Google.AI.Edge.LiteRT.CompiledModel.Options.GpuOptions.set -> void
Google.AI.Edge.LiteRT.CompiledModel.Options.Options(System.Collections.Generic.ICollection<Google.AI.Edge.LiteRT.Accelerator!>! accelerators) -> void
Google.AI.Edge.LiteRT.CompiledModel.Options.Options(params Google.AI.Edge.LiteRT.Accelerator![]! accelerators) -> void
Google.AI.Edge.LiteRT.CompiledModel.Options.QualcommOptions.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions?
Google.AI.Edge.LiteRT.CompiledModel.Options.QualcommOptions.set -> void
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component1() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component10() -> string?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component11() -> string?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component12() -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component13() -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component14() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component2() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component3() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component4() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component5() -> System.Collections.Generic.IList<Java.Lang.Integer!>?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component6() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component7() -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component8() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Component9() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Copy(Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel? logLevel, Java.Lang.Boolean? useHtpPreference, Java.Lang.Boolean? useQint16AsQuint16, Java.Lang.Boolean? enableWeightSharing, System.Collections.Generic.IList<Java.Lang.Integer!>? dumpTensorIds, Java.Lang.Boolean? useConvHmx, Java.Lang.Boolean? useFoldRelu, Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode? htpPerformanceMode, Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling? profiling, string? irJsonDir, string? dlcDir, Java.Lang.Integer? vtcmSize, Java.Lang.Integer? numHvxThreads, Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel? optimizationLevel) -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions!
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.DlcDir.get -> string?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.DumpTensorIds.get -> System.Collections.Generic.IList<Java.Lang.Integer!>?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.EnableWeightSharing.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.GetHtpPerformanceMode() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.GetLogLevel() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.GetOptimizationLevel() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.GetProfiling() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.IrJsonDir.get -> string?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.NumHvxThreads.get -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Value.get -> int
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.QualcommOptions() -> void
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.QualcommOptions(Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel? logLevel, Java.Lang.Boolean? useHtpPreference, Java.Lang.Boolean? useQint16AsQuint16, Java.Lang.Boolean? enableWeightSharing, System.Collections.Generic.IList<Java.Lang.Integer!>? dumpTensorIds, Java.Lang.Boolean? useConvHmx, Java.Lang.Boolean? useFoldRelu, Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode? htpPerformanceMode, Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling? profiling, string? irJsonDir, string? dlcDir, Java.Lang.Integer? vtcmSize, Java.Lang.Integer? numHvxThreads, Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel? optimizationLevel) -> void
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.UseConvHmx.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.UseFoldRelu.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.UseHtpPreference.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.UseQint16AsQuint16.get -> Java.Lang.Boolean?
Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.VtcmSize.get -> Java.Lang.Integer?
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IDictionary<string!, Google.AI.Edge.LiteRT.TensorBuffer!>! inputs, System.Collections.Generic.IDictionary<string!, Google.AI.Edge.LiteRT.TensorBuffer!>! outputs, string! signature) -> void
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! inputs) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! inputs, System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! outputs) -> void
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! inputs, System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! outputs, int signatureIndex) -> void
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! inputs, System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! outputs, string! signature) -> void
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! inputs, int signatureIndex) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.CompiledModel.Run(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>! inputs, string! signature) -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBuffer!>!
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.AiPackModelProvider(Android.Content.Context! context, string! aiPackName, string! modelPath, Kotlin.Jvm.Functions.IFunction0! acceleratorsProvider) -> void
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.AiPackModelProvider(Android.Content.Context! context, string! aiPackName, string! modelPath, System.Collections.Generic.ICollection<Google.AI.Edge.LiteRT.Accelerator!>! accelerators) -> void
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.AiPackModelProvider(Android.Content.Context! context, string! aiPackName, string! modelPath, params Google.AI.Edge.LiteRT.Accelerator![]! accelerators) -> void
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.Companion
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.CompatibleAccelerators.get -> System.Collections.Generic.ICollection<Google.AI.Edge.LiteRT.Accelerator!>!
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.Download(Kotlin.Coroutines.IContinuation! _completion) -> Java.Lang.Object?
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.InterfaceConsts
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.IsReady.get -> bool
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.Path.get -> string!
Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.Type.get -> Google.AI.Edge.LiteRT.ModelProviderType!
Google.AI.Edge.LiteRT.Environment
Google.AI.Edge.LiteRT.Environment.AvailableAccelerators.get -> System.Collections.Generic.ICollection<Google.AI.Edge.LiteRT.Accelerator!>!
Google.AI.Edge.LiteRT.Environment.Companion
Google.AI.Edge.LiteRT.Environment.Companion.Create() -> Google.AI.Edge.LiteRT.Environment!
Google.AI.Edge.LiteRT.Environment.Companion.Create(Google.AI.Edge.LiteRT.INpuAcceleratorProvider! npuAcceleratorProvider) -> Google.AI.Edge.LiteRT.Environment!
Google.AI.Edge.LiteRT.Environment.Companion.Create(Google.AI.Edge.LiteRT.INpuAcceleratorProvider! npuAcceleratorProvider, System.Collections.Generic.IDictionary<Google.AI.Edge.LiteRT.Environment.Option!, string!>! options) -> Google.AI.Edge.LiteRT.Environment!
Google.AI.Edge.LiteRT.Environment.Companion.Create(System.Collections.Generic.IDictionary<Google.AI.Edge.LiteRT.Environment.Option!, string!>! options) -> Google.AI.Edge.LiteRT.Environment!
Google.AI.Edge.LiteRT.Environment.Option
Google.AI.Edge.LiteRT.Environment.Option.Value.get -> int
Google.AI.Edge.LiteRT.IModelProvider
Google.AI.Edge.LiteRT.IModelProvider.Companion.get -> Google.AI.Edge.LiteRT.ModelProviderCompanion!
Google.AI.Edge.LiteRT.IModelProvider.CompatibleAccelerators.get -> System.Collections.Generic.ICollection<Google.AI.Edge.LiteRT.Accelerator!>!
Google.AI.Edge.LiteRT.IModelProvider.Download(Kotlin.Coroutines.IContinuation! _completion) -> Java.Lang.Object?
Google.AI.Edge.LiteRT.IModelProvider.DownloadFuture(AndroidX.Lifecycle.ILifecycleOwner! lifecycleOwner) -> Google.Common.Util.Concurrent.IListenableFuture!
Google.AI.Edge.LiteRT.IModelProvider.IsReady.get -> bool
Google.AI.Edge.LiteRT.IModelProvider.Path.get -> string!
Google.AI.Edge.LiteRT.IModelProvider.StaticModel(Google.AI.Edge.LiteRT.ModelProviderType! type, string! path, params Google.AI.Edge.LiteRT.Accelerator![]! accelerators) -> Google.AI.Edge.LiteRT.IModelProvider!
Google.AI.Edge.LiteRT.IModelProvider.Type.get -> Google.AI.Edge.LiteRT.ModelProviderType!
Google.AI.Edge.LiteRT.INpuAcceleratorProvider
Google.AI.Edge.LiteRT.INpuAcceleratorProvider.DownloadLibrary(Kotlin.Coroutines.IContinuation! _completion) -> Java.Lang.Object?
Google.AI.Edge.LiteRT.INpuAcceleratorProvider.IsDeviceSupported.get -> bool
Google.AI.Edge.LiteRT.INpuAcceleratorProvider.IsLibraryReady.get -> bool
Google.AI.Edge.LiteRT.INpuAcceleratorProvider.LibraryDir.get -> string!
Google.AI.Edge.LiteRT.INpuCompatibilityChecker
Google.AI.Edge.LiteRT.INpuCompatibilityChecker.Companion.get -> Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion!
Google.AI.Edge.LiteRT.INpuCompatibilityChecker.IsDeviceSupported.get -> bool
Google.AI.Edge.LiteRT.JniHandle
Google.AI.Edge.LiteRT.JniHandle.AssertNotDestroyed() -> void
Google.AI.Edge.LiteRT.JniHandle.Close() -> void
Google.AI.Edge.LiteRT.JniHandle.JniHandle(nint javaReference, Android.Runtime.JniHandleOwnership transfer) -> void
Google.AI.Edge.LiteRT.LiteRtException
Google.AI.Edge.LiteRT.LiteRtException.LiteRtException(Google.AI.Edge.LiteRT.Status! status, string! message) -> void
Google.AI.Edge.LiteRT.LiteRtException.LiteRtException(int code, string! message) -> void
Google.AI.Edge.LiteRT.ModelProvider
Google.AI.Edge.LiteRT.ModelProviderCompanion
Google.AI.Edge.LiteRT.ModelProviderCompanion.StaticModel(Google.AI.Edge.LiteRT.ModelProviderType! type, string! path, params Google.AI.Edge.LiteRT.Accelerator![]! accelerators) -> Google.AI.Edge.LiteRT.IModelProvider!
Google.AI.Edge.LiteRT.ModelProviderConsts
Google.AI.Edge.LiteRT.ModelProviderType
Google.AI.Edge.LiteRT.ModelSelector
Google.AI.Edge.LiteRT.ModelSelector.Companion
Google.AI.Edge.LiteRT.ModelSelector.ModelSelector(System.Collections.Generic.ICollection<Google.AI.Edge.LiteRT.IModelProvider!>! modelProviders) -> void
Google.AI.Edge.LiteRT.ModelSelector.ModelSelector(params Google.AI.Edge.LiteRT.IModelProvider![]! modelProviders) -> void
Google.AI.Edge.LiteRT.ModelSelector.SelectModel(Google.AI.Edge.LiteRT.Environment! env, Kotlin.Coroutines.IContinuation! _completion) -> Java.Lang.Object?
Google.AI.Edge.LiteRT.ModelSelector.SelectModelFuture(Google.AI.Edge.LiteRT.Environment! env, AndroidX.Lifecycle.ILifecycleOwner! lifecycleOwner) -> Google.Common.Util.Concurrent.IListenableFuture!
Google.AI.Edge.LiteRT.NpuCompatibilityChecker
Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion
Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion.Default.get -> Google.AI.Edge.LiteRT.INpuCompatibilityChecker!
Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion.GoogleTensor.get -> Google.AI.Edge.LiteRT.INpuCompatibilityChecker!
Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion.Mediatek.get -> Google.AI.Edge.LiteRT.INpuCompatibilityChecker!
Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion.Qualcomm.get -> Google.AI.Edge.LiteRT.INpuCompatibilityChecker!
Google.AI.Edge.LiteRT.NpuCompatibilityCheckerConsts
Google.AI.Edge.LiteRT.Status
Google.AI.Edge.LiteRT.Status.Code.get -> int
Google.AI.Edge.LiteRT.Status.Companion
Google.AI.Edge.LiteRT.Status.Companion.FromCode(int code) -> Google.AI.Edge.LiteRT.Status!
Google.AI.Edge.LiteRT.TensorBuffer
Google.AI.Edge.LiteRT.TensorBuffer.Companion
Google.AI.Edge.LiteRT.TensorBuffer.ReadBoolean() -> bool[]!
Google.AI.Edge.LiteRT.TensorBuffer.ReadFloat() -> float[]!
Google.AI.Edge.LiteRT.TensorBuffer.ReadInt() -> int[]!
Google.AI.Edge.LiteRT.TensorBuffer.ReadInt8() -> byte[]!
Google.AI.Edge.LiteRT.TensorBuffer.ReadLong() -> long[]!
Google.AI.Edge.LiteRT.TensorBuffer.WriteBoolean(bool[]! data) -> void
Google.AI.Edge.LiteRT.TensorBuffer.WriteFloat(float[]! data) -> void
Google.AI.Edge.LiteRT.TensorBuffer.WriteInt(int[]! data) -> void
Google.AI.Edge.LiteRT.TensorBuffer.WriteInt8(byte[]! data) -> void
Google.AI.Edge.LiteRT.TensorBuffer.WriteLong(long[]! data) -> void
Google.AI.Edge.LiteRT.TensorBufferRequirements
Google.AI.Edge.LiteRT.TensorBufferRequirements.BufferSize.get -> int
Google.AI.Edge.LiteRT.TensorBufferRequirements.Component1() -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBufferType!>!
Google.AI.Edge.LiteRT.TensorBufferRequirements.Component2() -> int
Google.AI.Edge.LiteRT.TensorBufferRequirements.Component3() -> System.Collections.Generic.IList<Java.Lang.Integer!>!
Google.AI.Edge.LiteRT.TensorBufferRequirements.Copy(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBufferType!>! supportedTypes, int bufferSize, System.Collections.Generic.IList<Java.Lang.Integer!>! strides) -> Google.AI.Edge.LiteRT.TensorBufferRequirements!
Google.AI.Edge.LiteRT.TensorBufferRequirements.Strides.get -> System.Collections.Generic.IList<Java.Lang.Integer!>!
Google.AI.Edge.LiteRT.TensorBufferRequirements.SupportedTypes.get -> System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBufferType!>!
Google.AI.Edge.LiteRT.TensorBufferRequirements.TensorBufferRequirements(System.Collections.Generic.IList<Google.AI.Edge.LiteRT.TensorBufferType!>! supportedTypes, int bufferSize, System.Collections.Generic.IList<Java.Lang.Integer!>! strides) -> void
Google.AI.Edge.LiteRT.TensorBufferRequirements.TensorBufferRequirements(int[]! supportedTypes, int bufferSize, int[]! strides) -> void
Google.AI.Edge.LiteRT.TensorBufferType
Google.AI.Edge.LiteRT.TensorBufferType.Companion
Google.AI.Edge.LiteRT.TensorBufferType.Companion.Of(int type) -> Google.AI.Edge.LiteRT.TensorBufferType!
Google.AI.Edge.LiteRT.TensorType
Google.AI.Edge.LiteRT.TensorType.Component1() -> Google.AI.Edge.LiteRT.TensorType.ElementType!
Google.AI.Edge.LiteRT.TensorType.Component2() -> Google.AI.Edge.LiteRT.TensorType.Layout?
Google.AI.Edge.LiteRT.TensorType.Copy(Google.AI.Edge.LiteRT.TensorType.ElementType! elementType, Google.AI.Edge.LiteRT.TensorType.Layout? layout) -> Google.AI.Edge.LiteRT.TensorType!
Google.AI.Edge.LiteRT.TensorType.ElementType
Google.AI.Edge.LiteRT.TensorType.GetElementType() -> Google.AI.Edge.LiteRT.TensorType.ElementType!
Google.AI.Edge.LiteRT.TensorType.GetLayout() -> Google.AI.Edge.LiteRT.TensorType.Layout?
Google.AI.Edge.LiteRT.TensorType.Layout
Google.AI.Edge.LiteRT.TensorType.Layout.Component1() -> System.Collections.Generic.IList<Java.Lang.Integer!>!
Google.AI.Edge.LiteRT.TensorType.Layout.Component2() -> System.Collections.Generic.IList<Java.Lang.Integer!>!
Google.AI.Edge.LiteRT.TensorType.Layout.Copy(System.Collections.Generic.IList<Java.Lang.Integer!>! dimensions, System.Collections.Generic.IList<Java.Lang.Integer!>! strides) -> Google.AI.Edge.LiteRT.TensorType.Layout!
Google.AI.Edge.LiteRT.TensorType.Layout.Dimensions.get -> System.Collections.Generic.IList<Java.Lang.Integer!>!
Google.AI.Edge.LiteRT.TensorType.Layout.HasStrides.get -> bool
Google.AI.Edge.LiteRT.TensorType.Layout.Layout(System.Collections.Generic.IList<Java.Lang.Integer!>! dimensions) -> void
Google.AI.Edge.LiteRT.TensorType.Layout.Layout(System.Collections.Generic.IList<Java.Lang.Integer!>! dimensions, System.Collections.Generic.IList<Java.Lang.Integer!>! strides) -> void
Google.AI.Edge.LiteRT.TensorType.Layout.Layout(int[]! dimensions) -> void
Google.AI.Edge.LiteRT.TensorType.Layout.Layout(int[]! dimensions, int[]! strides) -> void
Google.AI.Edge.LiteRT.TensorType.Layout.Rank.get -> int
Google.AI.Edge.LiteRT.TensorType.Layout.Strides.get -> System.Collections.Generic.IList<Java.Lang.Integer!>!
Google.AI.Edge.LiteRT.TensorType.TensorType(Google.AI.Edge.LiteRT.TensorType.ElementType! elementType) -> void
Google.AI.Edge.LiteRT.TensorType.TensorType(Google.AI.Edge.LiteRT.TensorType.ElementType! elementType, Google.AI.Edge.LiteRT.TensorType.Layout? layout) -> void
Xamarin.TensorFlow.Lite.Annotations.IUsedByReflection
Xamarin.TensorFlow.Lite.Annotations.IUsedByReflection.Value() -> string?
Xamarin.TensorFlow.Lite.Annotations.UsedByReflectionAttribute
Xamarin.TensorFlow.Lite.Annotations.UsedByReflectionAttribute.UsedByReflectionAttribute() -> void
Xamarin.TensorFlow.Lite.Annotations.UsedByReflectionAttribute.Value.get -> string?
Xamarin.TensorFlow.Lite.Annotations.UsedByReflectionAttribute.Value.set -> void
Xamarin.TensorFlow.Lite.DataType
Xamarin.TensorFlow.Lite.DataType.ByteSize() -> int
Xamarin.TensorFlow.Lite.IInterpreterApi
Xamarin.TensorFlow.Lite.IInterpreterApi.AllocateTensors() -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.Close() -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.Create(Java.IO.File? modelFile, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
Xamarin.TensorFlow.Lite.IInterpreterApi.Create(Java.Nio.ByteBuffer? byteBuffer, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetInputIndex(string? opName) -> int
Xamarin.TensorFlow.Lite.IInterpreterApi.GetInputTensor(int inputIndex) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetInputTensorFromSignature(string? inputName, string? signatureKey) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetOutputIndex(string? opName) -> int
Xamarin.TensorFlow.Lite.IInterpreterApi.GetOutputTensor(int outputIndex) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetOutputTensorFromSignature(string? outputName, string? signatureKey) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetSignatureInputs(string? signatureKey) -> string![]?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetSignatureKeys() -> string![]?
Xamarin.TensorFlow.Lite.IInterpreterApi.GetSignatureOutputs(string? signatureKey) -> string![]?
Xamarin.TensorFlow.Lite.IInterpreterApi.InputTensorCount.get -> int
Xamarin.TensorFlow.Lite.IInterpreterApi.LastNativeInferenceDurationNanoseconds.get -> Java.Lang.Long?
Xamarin.TensorFlow.Lite.IInterpreterApi.OutputTensorCount.get -> int
Xamarin.TensorFlow.Lite.IInterpreterApi.ResizeInput(int idx, int[]? dims) -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.ResizeInput(int idx, int[]? dims, bool strict) -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.Run(Java.Lang.Object? input, Java.Lang.Object? output) -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.RunForMultipleInputsOutputs(Java.Lang.Object![]? inputs, System.Collections.Generic.IDictionary<Java.Lang.Integer!, Java.Lang.Object!>? outputs) -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.RunSignature(System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? inputs, System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? outputs) -> void
Xamarin.TensorFlow.Lite.IInterpreterApi.RunSignature(System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? inputs, System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? outputs, string? signatureKey) -> void
Xamarin.TensorFlow.Lite.IInterpreterFactoryApi
Xamarin.TensorFlow.Lite.IInterpreterFactoryApi.Create(Java.IO.File? modelFile, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
Xamarin.TensorFlow.Lite.IInterpreterFactoryApi.Create(Java.Nio.ByteBuffer? byteBuffer, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
Xamarin.TensorFlow.Lite.IInterpreterFactoryApi.RuntimeVersion() -> string?
Xamarin.TensorFlow.Lite.IInterpreterFactoryApi.SchemaVersion() -> string?
Xamarin.TensorFlow.Lite.ITensor
Xamarin.TensorFlow.Lite.ITensor.AsReadOnlyBuffer() -> Java.Nio.ByteBuffer?
Xamarin.TensorFlow.Lite.ITensor.DataType() -> Xamarin.TensorFlow.Lite.DataType?
Xamarin.TensorFlow.Lite.ITensor.Index() -> int
Xamarin.TensorFlow.Lite.ITensor.Name() -> string?
Xamarin.TensorFlow.Lite.ITensor.NumBytes() -> int
Xamarin.TensorFlow.Lite.ITensor.NumDimensions() -> int
Xamarin.TensorFlow.Lite.ITensor.NumElements() -> int
Xamarin.TensorFlow.Lite.ITensor.QuantizationParams() -> Xamarin.TensorFlow.Lite.TensorQuantizationParams?
Xamarin.TensorFlow.Lite.ITensor.Shape() -> int[]?
Xamarin.TensorFlow.Lite.ITensor.ShapeSignature() -> int[]?
Xamarin.TensorFlow.Lite.Interpreter
Xamarin.TensorFlow.Lite.Interpreter.AllocateTensors() -> void
Xamarin.TensorFlow.Lite.Interpreter.Close() -> void
Xamarin.TensorFlow.Lite.Interpreter.GetInputIndex(string? opName) -> int
Xamarin.TensorFlow.Lite.Interpreter.GetInputTensor(int inputIndex) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.Interpreter.GetInputTensorFromSignature(string? inputName, string? signatureKey) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.Interpreter.GetOutputIndex(string? opName) -> int
Xamarin.TensorFlow.Lite.Interpreter.GetOutputTensor(int outputIndex) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.Interpreter.GetOutputTensorFromSignature(string? outputName, string? signatureKey) -> Xamarin.TensorFlow.Lite.ITensor?
Xamarin.TensorFlow.Lite.Interpreter.GetSignatureInputs(string? signatureKey) -> string![]?
Xamarin.TensorFlow.Lite.Interpreter.GetSignatureKeys() -> string![]?
Xamarin.TensorFlow.Lite.Interpreter.GetSignatureOutputs(string? signatureKey) -> string![]?
Xamarin.TensorFlow.Lite.Interpreter.InputTensorCount.get -> int
Xamarin.TensorFlow.Lite.Interpreter.Interpreter(Java.IO.File? modelFile) -> void
Xamarin.TensorFlow.Lite.Interpreter.Interpreter(Java.IO.File? modelFile, Xamarin.TensorFlow.Lite.Interpreter.Options? options) -> void
Xamarin.TensorFlow.Lite.Interpreter.Interpreter(Java.Nio.ByteBuffer? byteBuffer) -> void
Xamarin.TensorFlow.Lite.Interpreter.Interpreter(Java.Nio.ByteBuffer? byteBuffer, Xamarin.TensorFlow.Lite.Interpreter.Options? options) -> void
Xamarin.TensorFlow.Lite.Interpreter.LastNativeInferenceDurationNanoseconds.get -> Java.Lang.Long?
Xamarin.TensorFlow.Lite.Interpreter.Options
Xamarin.TensorFlow.Lite.Interpreter.Options.Options() -> void
Xamarin.TensorFlow.Lite.Interpreter.Options.Options(Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> void
Xamarin.TensorFlow.Lite.Interpreter.Options.Options(nint javaReference, Android.Runtime.JniHandleOwnership transfer) -> void
Xamarin.TensorFlow.Lite.Interpreter.OutputTensorCount.get -> int
Xamarin.TensorFlow.Lite.Interpreter.ResetVariableTensors() -> void
Xamarin.TensorFlow.Lite.Interpreter.ResizeInput(int idx, int[]? dims) -> void
Xamarin.TensorFlow.Lite.Interpreter.ResizeInput(int idx, int[]? dims, bool strict) -> void
Xamarin.TensorFlow.Lite.Interpreter.Run(Java.Lang.Object? input, Java.Lang.Object? output) -> void
Xamarin.TensorFlow.Lite.Interpreter.RunForMultipleInputsOutputs(Java.Lang.Object![]? inputs, System.Collections.Generic.IDictionary<Java.Lang.Integer!, Java.Lang.Object!>? outputs) -> void
Xamarin.TensorFlow.Lite.Interpreter.RunForMultipleInputsOutputs(Java.Lang.Object![]? inputs, System.Collections.IDictionary? outputs) -> void
Xamarin.TensorFlow.Lite.Interpreter.RunSignature(System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? inputs, System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? outputs) -> void
Xamarin.TensorFlow.Lite.Interpreter.RunSignature(System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? inputs, System.Collections.Generic.IDictionary<string!, Java.Lang.Object!>? outputs, string? signatureKey) -> void
Xamarin.TensorFlow.Lite.Interpreter.RunSignature(System.Collections.IDictionary? inputs, System.Collections.IDictionary? outputs) -> void
Xamarin.TensorFlow.Lite.Interpreter.RunSignature(System.Collections.IDictionary? inputs, System.Collections.IDictionary? outputs, string? signatureKey) -> void
Xamarin.TensorFlow.Lite.Interpreter.SetCancelled(bool cancelled) -> void
Xamarin.TensorFlow.Lite.InterpreterApi
Xamarin.TensorFlow.Lite.InterpreterApiConsts
Xamarin.TensorFlow.Lite.InterpreterApiOptions
Xamarin.TensorFlow.Lite.InterpreterApiOptions.InterpreterApiOptions() -> void
Xamarin.TensorFlow.Lite.InterpreterApiOptions.InterpreterApiOptions(Xamarin.TensorFlow.Lite.InterpreterApiOptions? other) -> void
Xamarin.TensorFlow.Lite.InterpreterApiOptions.InterpreterApiOptions(nint javaReference, Android.Runtime.JniHandleOwnership transfer) -> void
Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime
Xamarin.TensorFlow.Lite.InterpreterFactory
Xamarin.TensorFlow.Lite.InterpreterFactory.InterpreterFactory() -> void
Xamarin.TensorFlow.Lite.InterpreterFactory.InterpreterFactory(nint javaReference, Android.Runtime.JniHandleOwnership transfer) -> void
Xamarin.TensorFlow.Lite.RuntimeFlavor
Xamarin.TensorFlow.Lite.TensorFlowLite
Xamarin.TensorFlow.Lite.TensorQuantizationParams
Xamarin.TensorFlow.Lite.TensorQuantizationParams.TensorQuantizationParams(float scale, int zeroPoint) -> void
Xamarin.TensorFlow.Lite.TensorQuantizationParams.TensorQuantizationParams(nint javaReference, Android.Runtime.JniHandleOwnership transfer) -> void
abstract Google.AI.Edge.LiteRT.JniHandle.Destroy() -> void
override Google.AI.Edge.LiteRT.Accelerator.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Accelerator.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.BuiltinNpuAcceleratorProvider.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.CpuOptions.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.Options.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.Options.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Environment.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Environment.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Environment.Option.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.JniHandle.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.JniHandle.ThresholdClass.get -> nint
override Google.AI.Edge.LiteRT.JniHandle.ThresholdType.get -> System.Type!
override Google.AI.Edge.LiteRT.LiteRtException.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.ModelProviderCompanion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.ModelProviderType.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.ModelSelector.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.ModelSelector.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Status.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.Status.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorBuffer.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorBuffer.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorBufferRequirements.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorBufferType.Companion.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorBufferType.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorType.ElementType.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorType.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Google.AI.Edge.LiteRT.TensorType.Layout.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.DataType.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.Interpreter.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.Interpreter.Options.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.Interpreter.Options.ThresholdClass.get -> nint
override Xamarin.TensorFlow.Lite.Interpreter.Options.ThresholdType.get -> System.Type!
override Xamarin.TensorFlow.Lite.InterpreterApiOptions.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.InterpreterApiOptions.ThresholdClass.get -> nint
override Xamarin.TensorFlow.Lite.InterpreterApiOptions.ThresholdType.get -> System.Type!
override Xamarin.TensorFlow.Lite.InterpreterFactory.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.InterpreterFactory.ThresholdClass.get -> nint
override Xamarin.TensorFlow.Lite.InterpreterFactory.ThresholdType.get -> System.Type!
override Xamarin.TensorFlow.Lite.RuntimeFlavor.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.TensorFlowLite.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.TensorQuantizationParams.JniPeerMembers.get -> Java.Interop.JniPeerMembers!
override Xamarin.TensorFlow.Lite.TensorQuantizationParams.ThresholdClass.get -> nint
override Xamarin.TensorFlow.Lite.TensorQuantizationParams.ThresholdType.get -> System.Type!
static Google.AI.Edge.LiteRT.Accelerator.Cpu.get -> Google.AI.Edge.LiteRT.Accelerator?
static Google.AI.Edge.LiteRT.Accelerator.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.Accelerator.Gpu.get -> Google.AI.Edge.LiteRT.Accelerator?
static Google.AI.Edge.LiteRT.Accelerator.None.get -> Google.AI.Edge.LiteRT.Accelerator?
static Google.AI.Edge.LiteRT.Accelerator.Npu.get -> Google.AI.Edge.LiteRT.Accelerator?
static Google.AI.Edge.LiteRT.Accelerator.ValueOf(string? value) -> Google.AI.Edge.LiteRT.Accelerator?
static Google.AI.Edge.LiteRT.Accelerator.Values() -> Google.AI.Edge.LiteRT.Accelerator![]?
static Google.AI.Edge.LiteRT.CompiledModel.Create(Android.Content.Res.AssetManager! assetManager, string! assetName) -> Google.AI.Edge.LiteRT.CompiledModel!
static Google.AI.Edge.LiteRT.CompiledModel.Create(Android.Content.Res.AssetManager! assetManager, string! assetName, Google.AI.Edge.LiteRT.CompiledModel.Options! options) -> Google.AI.Edge.LiteRT.CompiledModel!
static Google.AI.Edge.LiteRT.CompiledModel.Create(Android.Content.Res.AssetManager! assetManager, string! assetName, Google.AI.Edge.LiteRT.CompiledModel.Options! options, Google.AI.Edge.LiteRT.Environment? optionalEnv) -> Google.AI.Edge.LiteRT.CompiledModel!
static Google.AI.Edge.LiteRT.CompiledModel.Create(string! filePath) -> Google.AI.Edge.LiteRT.CompiledModel!
static Google.AI.Edge.LiteRT.CompiledModel.Create(string! filePath, Google.AI.Edge.LiteRT.CompiledModel.Options! options) -> Google.AI.Edge.LiteRT.CompiledModel!
static Google.AI.Edge.LiteRT.CompiledModel.Create(string! filePath, Google.AI.Edge.LiteRT.CompiledModel.Options! options, Google.AI.Edge.LiteRT.Environment? optionalEnv) -> Google.AI.Edge.LiteRT.CompiledModel!
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.Automatic.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.Opencl.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.Values() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend![]?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend.Webgpu.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Backend?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.Buffer.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.Default.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.Texture2d.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType.Values() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.BufferStorageType![]?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.Default.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.Fp16.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.Fp32.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision.Values() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Precision![]?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.Default.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.High.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.Low.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.Normal.get -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority?
static Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority.Values() -> Google.AI.Edge.LiteRT.CompiledModel.GpuOptions.Priority![]?
static Google.AI.Edge.LiteRT.CompiledModel.Options.CPU.get -> Google.AI.Edge.LiteRT.CompiledModel.Options!
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.Balanced.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.Burst.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.Default.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.ExtremePowerSaver.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.HighPerformance.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.HighPowerSaver.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.LowBalanced.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.LowPowerSaver.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.PowerSaver.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.SustainedHighPerformance.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode.Values() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.HtpPerformanceMode![]?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Debug.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Error.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Info.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Off.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Values() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel![]?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Verbose.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel.Warn.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.LogLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.HtpOptimizeForInference.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.HtpOptimizeForInferenceO3.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.HtpOptimizeForPrepare.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel.Values() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.OptimizationLevel![]?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Basic.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Detailed.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Linting.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Off.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Optrace.get -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.ValueOf(string? value) -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling?
static Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling.Values() -> Google.AI.Edge.LiteRT.CompiledModel.QualcommOptions.Profiling![]?
static Google.AI.Edge.LiteRT.Deployment.AiPackModelProvider.InterfaceConsts.Companion.get -> Google.AI.Edge.LiteRT.ModelProviderCompanion!
static Google.AI.Edge.LiteRT.Environment.Create() -> Google.AI.Edge.LiteRT.Environment!
static Google.AI.Edge.LiteRT.Environment.Create(Google.AI.Edge.LiteRT.INpuAcceleratorProvider! npuAcceleratorProvider) -> Google.AI.Edge.LiteRT.Environment!
static Google.AI.Edge.LiteRT.Environment.Create(Google.AI.Edge.LiteRT.INpuAcceleratorProvider! npuAcceleratorProvider, System.Collections.Generic.IDictionary<Google.AI.Edge.LiteRT.Environment.Option!, string!>! options) -> Google.AI.Edge.LiteRT.Environment!
static Google.AI.Edge.LiteRT.Environment.Create(System.Collections.Generic.IDictionary<Google.AI.Edge.LiteRT.Environment.Option!, string!>! options) -> Google.AI.Edge.LiteRT.Environment!
static Google.AI.Edge.LiteRT.Environment.Option.CompilerPluginLibraryDir.get -> Google.AI.Edge.LiteRT.Environment.Option?
static Google.AI.Edge.LiteRT.Environment.Option.DispatchLibraryDir.get -> Google.AI.Edge.LiteRT.Environment.Option?
static Google.AI.Edge.LiteRT.Environment.Option.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.Environment.Option.ValueOf(string? value) -> Google.AI.Edge.LiteRT.Environment.Option?
static Google.AI.Edge.LiteRT.Environment.Option.Values() -> Google.AI.Edge.LiteRT.Environment.Option![]?
static Google.AI.Edge.LiteRT.ModelProvider.Companion.get -> Google.AI.Edge.LiteRT.ModelProviderCompanion!
static Google.AI.Edge.LiteRT.ModelProvider.StaticModel(Google.AI.Edge.LiteRT.ModelProviderType! type, string! path, params Google.AI.Edge.LiteRT.Accelerator![]! accelerators) -> Google.AI.Edge.LiteRT.IModelProvider!
static Google.AI.Edge.LiteRT.ModelProviderType.Asset.get -> Google.AI.Edge.LiteRT.ModelProviderType?
static Google.AI.Edge.LiteRT.ModelProviderType.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.ModelProviderType.File.get -> Google.AI.Edge.LiteRT.ModelProviderType?
static Google.AI.Edge.LiteRT.ModelProviderType.ValueOf(string? value) -> Google.AI.Edge.LiteRT.ModelProviderType?
static Google.AI.Edge.LiteRT.ModelProviderType.Values() -> Google.AI.Edge.LiteRT.ModelProviderType![]?
static Google.AI.Edge.LiteRT.NpuCompatibilityChecker.Companion.get -> Google.AI.Edge.LiteRT.NpuCompatibilityCheckerCompanion!
static Google.AI.Edge.LiteRT.Status.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.Status.ErrorAlreadyExists.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorCancelled.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorCompilation.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorDynamicLoading.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorFileIO.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorGraphModification.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorIndexOOB.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidArgument.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidFlatbuffer.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidGraphInvariant.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidIrType.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidLegalization.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidToolConfig.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorInvalidTransformation.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorMemoryAllocationFailure.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorMissingInputTensor.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorNotFound.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorRuntimeFailure.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorSerialization.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorTimeoutExpired.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorUnknown.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorUnsupported.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ErrorWrongVersion.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.LegalizeNoMatch.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.Ok.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.PatternNoMatch.get -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.ValueOf(string? value) -> Google.AI.Edge.LiteRT.Status?
static Google.AI.Edge.LiteRT.Status.Values() -> Google.AI.Edge.LiteRT.Status![]?
static Google.AI.Edge.LiteRT.TensorBufferType.Ahwb.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.DmaBuf.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.TensorBufferType.FastRpc.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.GlBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.GlTexture.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.HostMemory.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.Ion.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClBufferFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClBufferPacked.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClImageBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClImageBufferFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClTexture.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.OpenClTextureFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.Unknown.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.ValueOf(string? value) -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.Values() -> Google.AI.Edge.LiteRT.TensorBufferType![]?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanBufferFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanBufferPacked.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanImageBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanImageBufferFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanTexture.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.VulkanTextureFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuBufferFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuBufferPacked.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuImageBuffer.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuImageBufferFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuTexture.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorBufferType.WebGpuTextureFp16.get -> Google.AI.Edge.LiteRT.TensorBufferType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.Boolean.get -> Google.AI.Edge.LiteRT.TensorType.ElementType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.Entries.get -> Kotlin.Enums.IEnumEntries!
static Google.AI.Edge.LiteRT.TensorType.ElementType.Float.get -> Google.AI.Edge.LiteRT.TensorType.ElementType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.Int.get -> Google.AI.Edge.LiteRT.TensorType.ElementType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.Int64.get -> Google.AI.Edge.LiteRT.TensorType.ElementType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.Int8.get -> Google.AI.Edge.LiteRT.TensorType.ElementType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.ValueOf(string? value) -> Google.AI.Edge.LiteRT.TensorType.ElementType?
static Google.AI.Edge.LiteRT.TensorType.ElementType.Values() -> Google.AI.Edge.LiteRT.TensorType.ElementType![]?
static Xamarin.TensorFlow.Lite.DataType.Bool.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Float32.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Int16.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Int32.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Int64.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Int8.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.String.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Uint8.get -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.ValueOf(string? name) -> Xamarin.TensorFlow.Lite.DataType?
static Xamarin.TensorFlow.Lite.DataType.Values() -> Xamarin.TensorFlow.Lite.DataType![]?
static Xamarin.TensorFlow.Lite.InterpreterApi.Create(Java.IO.File? modelFile, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
static Xamarin.TensorFlow.Lite.InterpreterApi.Create(Java.Nio.ByteBuffer? byteBuffer, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
static Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime.FromApplicationOnly.get -> Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime?
static Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime.FromSystemOnly.get -> Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime?
static Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime.PreferSystemOverApplication.get -> Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime?
static Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime.ValueOf(string? name) -> Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime?
static Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime.Values() -> Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime![]?
static Xamarin.TensorFlow.Lite.RuntimeFlavor.Application.get -> Xamarin.TensorFlow.Lite.RuntimeFlavor?
static Xamarin.TensorFlow.Lite.RuntimeFlavor.System.get -> Xamarin.TensorFlow.Lite.RuntimeFlavor?
static Xamarin.TensorFlow.Lite.RuntimeFlavor.ValueOf(string? name) -> Xamarin.TensorFlow.Lite.RuntimeFlavor?
static Xamarin.TensorFlow.Lite.RuntimeFlavor.Values() -> Xamarin.TensorFlow.Lite.RuntimeFlavor![]?
static Xamarin.TensorFlow.Lite.TensorFlowLite.Init() -> void
static Xamarin.TensorFlow.Lite.TensorFlowLite.RuntimeVersion() -> string?
static Xamarin.TensorFlow.Lite.TensorFlowLite.RuntimeVersion(Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime? runtime) -> string?
static Xamarin.TensorFlow.Lite.TensorFlowLite.SchemaVersion() -> string?
static Xamarin.TensorFlow.Lite.TensorFlowLite.SchemaVersion(Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime? runtime) -> string?
static Xamarin.TensorFlow.Lite.TensorFlowLite.Version() -> string?
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.IsCancellable.get -> bool
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.NumThreads.get -> int
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.Runtime.get -> Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime?
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.SetCancellable(bool allow) -> Xamarin.TensorFlow.Lite.InterpreterApiOptions?
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.SetNumThreads(int numThreads) -> Xamarin.TensorFlow.Lite.InterpreterApiOptions?
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.SetRuntime(Xamarin.TensorFlow.Lite.InterpreterApiOptions.TfLiteRuntime? runtime) -> Xamarin.TensorFlow.Lite.InterpreterApiOptions?
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.SetUseXNNPACK(bool useXNNPACK) -> Xamarin.TensorFlow.Lite.InterpreterApiOptions?
virtual Xamarin.TensorFlow.Lite.InterpreterApiOptions.UseXNNPACK.get -> bool
virtual Xamarin.TensorFlow.Lite.InterpreterFactory.Create(Java.IO.File? modelFile, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
virtual Xamarin.TensorFlow.Lite.InterpreterFactory.Create(Java.Nio.ByteBuffer? byteBuffer, Xamarin.TensorFlow.Lite.InterpreterApiOptions? options) -> Xamarin.TensorFlow.Lite.IInterpreterApi?
virtual Xamarin.TensorFlow.Lite.TensorQuantizationParams.Scale.get -> float
virtual Xamarin.TensorFlow.Lite.TensorQuantizationParams.ZeroPoint.get -> int
